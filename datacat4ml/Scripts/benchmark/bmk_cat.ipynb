{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env: pyg (Python 3.9.16)\n",
    "\"\"\"\n",
    "build a benchmarking pipeline for machine learning models and save the results to result.csv\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "# inner modules\n",
    "from datacat4ml.const import *\n",
    "from datacat4ml.utils import mkdirs\n",
    "from datacat4ml.Scripts.model_dev.data_process import Data\n",
    "from datacat4ml.Scripts.model_dev.ml import RFC, RFR\n",
    "from datacat4ml.Scripts.model_dev.metrics import *\n",
    "from datacat4ml.Scripts.model_dev.tune_alpha_low import get_config\n",
    "\n",
    "#=========================Benchmarking==========================\n",
    "algo4reg = [RFR]\n",
    "algo4cls = [RFC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result_file, data, \n",
    "                  threshold=5, \n",
    "                  accuracy=\"None\", precision=\"None\",recall=\"None\", mcc=\"None\", bedroc_dec5=\"None\", bedroc_2=\"None\", bedroc_8=\"None\", \n",
    "                  rmse=\"None\", cliff_rmse=\"None\", r2=\"None\", cliff_r2=\"None\",\n",
    "                  file_path = SPLIT_CAT_DATASETS_DIR, task: str='cls', use_clustering: bool=True, use_smote: bool=True, \n",
    "                  descriptor: str='ECFP4', algoname=RFC):\n",
    "    \n",
    "    \"\"\"\n",
    "    Write benchmarking results to a file\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir = BMK_CAT_DIR\n",
    "    mkdirs(output_dir)\n",
    "    result_path= os.path.join(output_dir, result_file)\n",
    "\n",
    "    if file_path == SPLIT_CAT_DATASETS_DIR:\n",
    "        file_path_name = 'CAT_ORs'\n",
    "    elif file_path == SPLIT_HET_DATASETS_DIR:\n",
    "        file_path_name = 'HET_ORs'\n",
    "\n",
    "    n_compounds = len(data.y_train)+len(data.y_test)\n",
    "    n_compounds_train = len(data.y_train)\n",
    "    n_compounds_test = len(data.y_test)\n",
    "\n",
    "    if task == 'cls':\n",
    "        n_cliff_compounds = 'NA'\n",
    "        n_cliff_compounds_train = 'NA'\n",
    "        n_cliff_compounds_test = 'NA'\n",
    "    elif task == 'reg':\n",
    "        n_cliff_compounds = sum(data.cliff_mols_train)+sum(data.cliff_mols_test)\n",
    "        n_cliff_compounds_train = sum(data.cliff_mols_train)\n",
    "        n_cliff_compounds_test = sum(data.cliff_mols_test)\n",
    "\n",
    "\n",
    " \n",
    "    # Create output file if it doesn't exist already\n",
    "    if not os.path.isfile(result_path):\n",
    "        with open(result_path, 'w') as f:\n",
    "            f.write('file_path,task,use_clustering,use_smote,'\n",
    "                    'target,effect,assay,std_type,descriptor,algo,'\n",
    "                    'n_compounds,n_cliff_compounds,n_compounds_train,n_cliff_compounds_train,n_compounds_test,n_cliff_compounds_test,'\n",
    "                    'threshold, accuracy, precision, recall, mcc, bedroc_dec5, bedroc_2, bedroc_8,'\n",
    "                    'rmse, cliff_rmse, r2, cliff_r2\\n')\n",
    "            \n",
    "    with open(result_path, 'a') as f:\n",
    "        f.write(f'{file_path_name},{task},{use_clustering},{use_smote},'\n",
    "                f'{data.target},{data.effect},{data.assay},{data.std_type},{descriptor},{algoname},'\n",
    "                f'{n_compounds},{n_cliff_compounds},{n_compounds_train},{n_cliff_compounds_train},{n_compounds_test},{n_cliff_compounds_test},'\n",
    "                f'{threshold},{accuracy},{precision},{recall},{mcc},{bedroc_dec5},{bedroc_2},{bedroc_8},'\n",
    "                f'{rmse},{cliff_rmse},{r2},{cliff_r2} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_result(result_file: str = \"results_ml.csv\", file_path=SPLIT_CAT_DATASETS_DIR, task: str = 'cls',\n",
    "                     use_clustering: int=1, use_smote: int=1, descriptor: str='ECFP4'):\n",
    "    \n",
    "    use_clustering = bool(use_clustering)\n",
    "    use_smote = bool(use_smote)\n",
    "\n",
    "    print(f\"file_path: {file_path}\\n\")\n",
    "    print(f\"task: {task}\\n\")\n",
    "    print(f\"use_clustering: {use_clustering}\\n\")\n",
    "\n",
    "    file_folder = os.path.join(file_path, task, 'use_clustering' +'_'+str(use_clustering))\n",
    "    print(f\"file_folder is {file_folder}\")\n",
    "\n",
    "    filenames = os.listdir(file_folder)\n",
    "    print(f\"filenames is {filenames}\")\n",
    "    for filename in tqdm(filenames):\n",
    "        print(f\"file: {filename}\\n\")\n",
    "        df = pd.read_csv(os.path.join(file_folder, filename))\n",
    "        threshold = df['threshold'].iloc[0]\n",
    "        \n",
    "        print(f\"use_smote: {use_smote}\\n\")\n",
    "        if task == 'reg':\n",
    "            use_smote = False\n",
    "            algos = algo4reg\n",
    "        elif task == 'cls':\n",
    "            use_smote = use_smote\n",
    "            algos = algo4cls\n",
    "        \n",
    "        # create a Data object\n",
    "        try:\n",
    "            data = Data(file_folder, filename, task, use_smote)\n",
    "\n",
    "\n",
    "            print(f\"descriptor: {descriptor}\\n\")\n",
    "\n",
    "            # Featurize SMILES strings with the given descriptor\n",
    "            data.featurize_data(descriptor)            \n",
    "            \n",
    "            if task == 'cls' and use_smote:\n",
    "                data.balance_data()\n",
    "                data.shuffle()\n",
    "            else:\n",
    "                data.shuffle()\n",
    "\n",
    "            for algo in algos:\n",
    "                print(f\"algo: {algo.__name__}\\n\")\n",
    "                config_path = os.path.join(BEST_CONFIG_CAT_DIR, task, 'use_clustering' +'_'+str(use_clustering), \n",
    "                                        'use_smote'+'_'+str(use_smote), filename[:-10], f\"{algo.__name__}_{descriptor}.yml\")\n",
    "                model_path = os.path.join(MODELS_CAT_DIR, task, 'use_clustering' +'_'+str(use_clustering), \n",
    "                                            'use_smote'+'_'+str(use_smote), filename[:-10], f\"{algo.__name__}_{descriptor}.joblib\")\n",
    "                if not os.path.isdir(os.path.dirname(model_path)):\n",
    "                    os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "                try:\n",
    "                    # Get the best hyperparmeters stored in the config file\n",
    "                    print(f\"read best config ...\")\n",
    "                    best_config = get_config(config_path)\n",
    "                    print('Done')\n",
    "\n",
    "                    # Train the model with the best hyperparameters\n",
    "                    print(f\"train model ...\")\n",
    "                    f = algo(task, **best_config)\n",
    "\n",
    "                    if data.x_smote_train is not None:\n",
    "                        print(f\"smote is used\")\n",
    "                        f.train(data.x_smote_train, data.y_smote_train)\n",
    "                    else:\n",
    "                        print(f\"smote is not used\") \n",
    "                        f.train(data.x_train, data.y_train)\n",
    "                    print('Done')\n",
    "\n",
    "                    # Save the model\n",
    "                    print(f\"save model ...\")\n",
    "                    with open(model_path, 'wb') as handle:\n",
    "                        joblib.dump(f, handle)\n",
    "                    print('Done')\n",
    "\n",
    "                    # Evaluate the model\n",
    "                    print(f\"evaluate model ...\")\n",
    "                    y_pred = f.predict(data.x_test)\n",
    "                    if task == 'cls':\n",
    "                        accuracy = calc_accuracy(data.y_test, y_pred)\n",
    "                        precision = calc_precision(data.y_test, y_pred)\n",
    "                        recall = calc_recall(data.y_test, y_pred)\n",
    "                        mcc = calc_mcc(data.y_test, y_pred)\n",
    "                        y_pred_proba = f.predict_proba(data.x_test)\n",
    "                        bedroc_dec5 = calc_bedroc(y_pred_proba=y_pred_proba, y_true=data.y_test, alpha=321.9)\n",
    "                        bedroc_2 = calc_bedroc(y_pred_proba=y_pred_proba, y_true=data.y_test, alpha=80.5)\n",
    "                        bedroc_8 = calc_bedroc(y_pred_proba=y_pred_proba, y_true=data.y_test, alpha=20.0)\n",
    "\n",
    "                        r2, cliff_r2, rmse, cliff_rmse = None, None, None, None\n",
    "\n",
    "                    elif task == 'reg':\n",
    "                        r2 = calc_r2(data.y_test, y_pred)\n",
    "                        cliff_r2 = calc_cliff_r2(y_test_pred=y_pred, y_test=data.y_test,\n",
    "                                                cliff_mols_test=data.cliff_mols_test)\n",
    "                        rmse = calc_rmse(data.y_test, y_pred)\n",
    "                        cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=data.y_test,\n",
    "                                                        cliff_mols_test=data.cliff_mols_test)\n",
    "                        accuracy, precision, recall, mcc, bedroc_dec5, bedroc_2, bedroc_8 = None, None, None, None\n",
    "                    print('Done')\n",
    "                    \n",
    "                    # Write the results to a csv file\n",
    "                    print(f\"write results ...\")\n",
    "                    write_results(result_file=result_file, data=data, \n",
    "                                  threshold=threshold, \n",
    "                                  accuracy=accuracy, precision=precision,recall=recall,mcc=mcc, bedroc_dec5=bedroc_dec5, bedroc_2=bedroc_2,bedroc_8=bedroc_8, \n",
    "                                  rmse=rmse, cliff_rmse=cliff_rmse, r2=r2, cliff_r2=cliff_r2,\n",
    "                                  file_path=file_path, task=task, use_clustering=use_clustering, use_smote=use_smote, \n",
    "                                  descriptor=descriptor, algoname=algo.__name__)\n",
    "                    \n",
    "                    print(\"Done\")\n",
    "                    # check the results by loading it as a pandas dataframe\n",
    "                \n",
    "                    print('######################')\n",
    "\n",
    "                    \n",
    "                except:\n",
    "                        warnings.warn(f\" -- FAILED {filename}, {task}, use_smote_{use_smote}, {algo.__name__}-{descriptor}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            warnings.warn(f\" -- FAILED to create Data object for {filename}: {e} --\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== main ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Model building and benchmarking')\n",
    "    parser.add_argument('--result_file', type=str, required=True, help='path to the result file')\n",
    "    parser.add_argument('--file_path', type=str, required=True, help='path to the data folder')\n",
    "    parser.add_argument('--task', type=str, required=True, help='task: cls or reg')\n",
    "    parser.add_argument('--use_clustering', type=int, required=True, help='use clustering or not')\n",
    "    parser.add_argument('--use_smote', type=int, required=True, help='use smote or not')\n",
    "    parser.add_argument('--descriptor', type=str, required=True, help='descriptor')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    benchmark_result(result_file=args.result_file,\n",
    "                     file_path=args.file_path,\n",
    "                     task=args.task,\n",
    "                     use_clustering=args.use_clustering,\n",
    "                     use_smote=args.use_smote,\n",
    "                     descriptor=args.descriptor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
