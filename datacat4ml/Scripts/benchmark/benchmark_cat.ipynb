{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env: pyg (Python 3.9.16)\n",
    "\"\"\"\n",
    "build a benchmarking pipeline for machine learning models and save the results to result.csv\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import argparse\n",
    "\n",
    "# inner modules\n",
    "from datacat4ml.const import *\n",
    "from datacat4ml.Scripts.model_dev.data_process import Data\n",
    "from datacat4ml.Scripts.model_dev.ml import RFC, RFR, SVRR, SVCC, KNNR, KNNC, GBC, GBR\n",
    "from datacat4ml.Scripts.model_dev.metrics import *\n",
    "from datacat4ml.Scripts.model_dev.tune_alpha_low import get_config\n",
    "from datacat4ml.Scripts.utils import mkdirs\n",
    "\n",
    "#=========================Benchmarking==========================\n",
    "algo4reg = [RFR, SVRR, KNNR, GBR]\n",
    "algo4cls = [RFC, SVCC, KNNC, GBC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(result_file, data, mcc=None, bedroc_dec5=None, bedroc_2=None, bedroc_8=None, rmse=None, cliff_rmse=None, r2=None, cliff_r2=None,\n",
    "                  file_path: File_paths=DATASETS_DIR, task: str='cls', confidence_score: int=8, thr_class: int=6, use_clustering: bool=True, use_smote: bool=True, \n",
    "                  descriptor: str='ECFP4', algoname: Algos=RFC):\n",
    "    \n",
    "    \"\"\"\n",
    "    Write benchmarking results to a file\n",
    "    \"\"\"\n",
    "\n",
    "    output_dir = RESULTS_ASSAYWISE_DIR\n",
    "    mkdirs(output_dir)\n",
    "    result_path= os.path.join(output_dir, result_file)\n",
    "\n",
    "    if file_path == DATASETS_DIR:\n",
    "        file_path_name = 'categorized'\n",
    "    elif file_path == FETCH_DATA_DIR:\n",
    "        file_path_name = 'merged'\n",
    "\n",
    " \n",
    "    # Create output file if it doesn't exist already\n",
    "    if not os.path.isfile(result_path):\n",
    "        with open(result_path, 'w') as f:\n",
    "            f.write('file_path,task,confidence_score,thr_class,use_clustering,use_smote,'\n",
    "                    'target,effect,assay,std_type,descriptor,algo,'\n",
    "                    'n_compounds,n_cliff_compounds,n_compounds_train,n_cliff_compounds_train,n_compounds_test,n_cliff_compounds_test,'\n",
    "                    'mcc,bedroc_dec5,bedroc_2,bedroc_8,rmse,cliff_rmse,r2,cliff_r2\\n')\n",
    "            \n",
    "    with open(result_path, 'a') as f:\n",
    "        f.write(f'{file_path_name},{task},{confidence_score},{thr_class},{use_clustering},{use_smote},'\n",
    "                f'{data.target},{data.effect},{data.assay},{data.std_type},{descriptor},{algoname},'\n",
    "                f'{len(data.y_train)+len(data.y_test)},{sum(data.cliff_mols_train)+sum(data.cliff_mols_test)},'\n",
    "                f'{len(data.y_train)},{sum(data.cliff_mols_train)},{len(data.y_test)},{sum(data.cliff_mols_test)},'\n",
    "                f'{mcc},{bedroc_dec5},{bedroc_2},{bedroc_8},{rmse},{cliff_rmse},{r2},{cliff_r2} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_result(result_file: str = \"results.csv\", file_path: File_paths=DATASETS_DIR, task: str = 'cls', \n",
    "                     confidence_score: int=8, thr_class: int=6, \n",
    "                     use_clustering: int=1, use_smote: int=1, descriptor: str='ECFP4'):\n",
    "    \n",
    "    use_clustering = bool(use_clustering)\n",
    "    use_smote = bool(use_smote)\n",
    "\n",
    "    print(f\"file_path: {file_path}\\n\")\n",
    "    print(f\"task: {task}\\n\")\n",
    "    print(f\"confidence_score: {confidence_score}\\n\")\n",
    "    print(f\"thr_class: {thr_class}\\n\")\n",
    "    print(f\"use_clustering: {use_clustering}\\n\")\n",
    "\n",
    "    file_folder = os.path.join(file_path, 'assaywise_splited', task, 'confidence_score'+'_'+str(confidence_score), \n",
    "                                'thr_class'+'_'+str(thr_class), 'use_clustering' +'_'+str(use_clustering))\n",
    "    print(f\"file_folder is {file_folder}\")\n",
    "\n",
    "    filenames = os.listdir(file_folder)\n",
    "    print(f\"filenames is {filenames}\")\n",
    "    for filename in tqdm(filenames):\n",
    "        print(f\"file: {filename}\\n\")\n",
    "\n",
    "        print(f\"use_smote: {use_smote}\\n\")\n",
    "        if task == 'reg':\n",
    "            use_smote = False\n",
    "            algos = algo4reg\n",
    "        elif task == 'cls':\n",
    "            use_smote = use_smote\n",
    "            algos = algo4cls\n",
    "        \n",
    "        # create a Data object\n",
    "        try:\n",
    "            data = Data(file_folder, filename, task, use_smote)\n",
    "\n",
    "\n",
    "            print(f\"descriptor: {descriptor}\\n\")\n",
    "\n",
    "            # Featurize SMILES strings with the given descriptor\n",
    "            data.featurize_data(descriptor)            \n",
    "            \n",
    "            if task == 'cls' and use_smote:\n",
    "                data.balance_data()\n",
    "                data.shuffle()\n",
    "            else:\n",
    "                data.shuffle()\n",
    "\n",
    "            for algo in algos:\n",
    "                print(f\"algo: {algo.__name__}\\n\")\n",
    "                config_path = os.path.join(BEST_CONFIG_ASSAYWISE_DIR, task, 'confidence_score'+'_'+str(confidence_score), \n",
    "                                        'thr_class'+'_'+str(thr_class), 'use_clustering' +'_'+str(use_clustering), \n",
    "                                        'use_smote'+'_'+str(use_smote), filename[:-10], f\"{algo.__name__}_{descriptor}.yml\")\n",
    "                model_path = os.path.join(MODELS_ASSAYWISE_DIR, task, 'confidence_score'+'_'+str(confidence_score), \n",
    "                                            'thr_class'+'_'+str(thr_class), 'use_clustering' +'_'+str(use_clustering), \n",
    "                                            'use_smote'+'_'+str(use_smote), filename[:-10], f\"{algo.__name__}_{descriptor}.joblib\")\n",
    "                if not os.path.isdir(os.path.dirname(model_path)):\n",
    "                    os.makedirs(os.path.dirname(model_path))\n",
    "\n",
    "                try:\n",
    "                    # Get the best hyperparmeters stored in the config file\n",
    "                    print(f\"read best config ...\")\n",
    "                    best_config = get_config(config_path)\n",
    "                    print('Done')\n",
    "\n",
    "                    # Train the model with the best hyperparameters\n",
    "                    print(f\"train model ...\")\n",
    "                    f = algo(task, **best_config)\n",
    "\n",
    "                    if data.x_smote_train is not None:\n",
    "                        print(f\"smote is used\")\n",
    "                        f.train(data.x_smote_train, data.y_smote_train)\n",
    "                    else:\n",
    "                        print(f\"smote is not used\") \n",
    "                        f.train(data.x_train, data.y_train)\n",
    "                    print('Done')\n",
    "\n",
    "                    # Save the model\n",
    "                    print(f\"save model ...\")\n",
    "                    with open(model_path, 'wb') as handle:\n",
    "                        joblib.dump(f, handle)\n",
    "                    print('Done')\n",
    "\n",
    "                    # Evaluate the model\n",
    "                    print(f\"evaluate model ...\")\n",
    "                    y_pred = f.predict(data.x_test)\n",
    "                    if task == 'cls':\n",
    "                        mcc = calc_mcc(data.y_test, y_pred)\n",
    "                        y_pred_proba = f.predict_proba(data.x_test)\n",
    "                        bedroc_dec5 = calc_bedroc(y_pred_proba=y_pred_proba, y_true=data.y_test, alpha=321.9)\n",
    "                        bedroc_2 = calc_bedroc(y_pred_proba=y_pred_proba, y_true=data.y_test, alpha=80.5)\n",
    "                        bedroc_8 = calc_bedroc(y_pred_proba=y_pred_proba, y_true=data.y_test, alpha=20.0)\n",
    "\n",
    "                        r2, cliff_r2, rmse, cliff_rmse = None, None, None, None\n",
    "\n",
    "                    elif task == 'reg':\n",
    "                        r2 = calc_r2(data.y_test, y_pred)\n",
    "                        cliff_r2 = calc_cliff_r2(y_test_pred=y_pred, y_test=data.y_test,\n",
    "                                                cliff_mols_test=data.cliff_mols_test)\n",
    "                        rmse = calc_rmse(data.y_test, y_pred)\n",
    "                        cliff_rmse = calc_cliff_rmse(y_test_pred=y_pred, y_test=data.y_test,\n",
    "                                                        cliff_mols_test=data.cliff_mols_test)\n",
    "                        mcc, bedroc_dec5, bedroc_2, bedroc_8 = None, None, None, None\n",
    "                    print('Done')\n",
    "                    \n",
    "                    # Write the results to a csv file\n",
    "                    print(f\"write results ...\")\n",
    "                    write_results(result_file=result_file, data=data, mcc=mcc, bedroc_dec5=bedroc_dec5, bedroc_2=bedroc_2,bedroc_8=bedroc_8, rmse=rmse, cliff_rmse=cliff_rmse, r2=r2, cliff_r2=cliff_r2,\n",
    "                                file_path=file_path, task=task, confidence_score=confidence_score, thr_class=thr_class, use_clustering=use_clustering, use_smote=use_smote, \n",
    "                                descriptor=descriptor, algoname=algo.__name__)\n",
    "                    \n",
    "                    print(\"Done\")\n",
    "                    # check the results by loading it as a pandas dataframe\n",
    "                \n",
    "                    print('######################')\n",
    "\n",
    "                    \n",
    "                except:\n",
    "                        warnings.warn(f\" -- FAILED {filename}, {task}, use_smote_{use_smote}, {algo.__name__}-{descriptor}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            warnings.warn(f\" -- FAILED to create Data object for {filename}: {e} --\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== main ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Model building and benchmarking')\n",
    "    parser.add_argument('--result_file', type=str, required=True, help='path to the result file')\n",
    "    parser.add_argument('--file_path', type=str, required=True, help='path to the data folder')\n",
    "    parser.add_argument('--task', type=str, required=True, help='task: cls or reg')\n",
    "    parser.add_argument('--confidence_score', type=int, required=True, help='confidence score')\n",
    "    parser.add_argument('--thr_class', type=int, required=True, help='threshold for class')\n",
    "    parser.add_argument('--use_clustering', type=int, required=True, help='use clustering or not')\n",
    "    parser.add_argument('--use_smote', type=int, required=True, help='use smote or not')\n",
    "    parser.add_argument('--descriptor', type=str, required=True, help='descriptor')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    benchmark_result(result_file=args.result_file,\n",
    "                     file_path=args.file_path,\n",
    "                     task=args.task,\n",
    "                     confidence_score=args.confidence_score,\n",
    "                     thr_class=args.thr_class,\n",
    "                     use_clustering=args.use_clustering,\n",
    "                     use_smote=args.use_smote,\n",
    "                     descriptor=args.descriptor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
