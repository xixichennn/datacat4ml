{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a1e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env: datacat (python=3.8.2)\n",
    "# for `pretrained.py`\n",
    "from pathlib import Path\n",
    "import json\n",
    "from loguru import logger\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from datacat.utils.encode_smiles import convert_smiles_to_fp\n",
    "\n",
    "# for `models.py`\n",
    "from typing import List, Tuple\n",
    "\n",
    "from datacat4ml.Scripts.data_prep.data_featurize.compound_featurize.encode_compound import convert_smiles_to_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c6fc7",
   "metadata": {},
   "source": [
    "# perceptron.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f579b",
   "metadata": {},
   "source": [
    "## `def msra_initialization(m)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a86820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msra_initialization(m): #?Yu does 'm' standards for matrix?\n",
    "    \"\"\"\n",
    "    MSRA intialization of the weights of a :class:`torch.nn.Module` (a layer),\n",
    "    that is, the weights of the layer are :math:`\\\\mathbf{W} \\\\sim N(0, 2 / D)`, \n",
    "    where :math:`D` is the incoming dimension. For more details, see paper:\n",
    "\n",
    "    .. `paper`: https://arxiv.org/abs/1502.01852\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    m: :class:`torch.nn.Module`\n",
    "        Module (layer) whose weights should be normalized.\n",
    "    \"\"\"\n",
    "    nn.init.normal_(m.weight, mean=0., std=np.sqrt(2. / m.in_features))\n",
    "    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673f0e5",
   "metadata": {},
   "source": [
    "## `class MultilayerPerceptron(nn.Module)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44763440",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron(nn.Module):\n",
    "    \"\"\"\n",
    "    Feed-forward neural network with `feature_size` input units, `num_targets` output units, and hidden layers given by the list `hidden_layer_sizes`.\n",
    "    The input layer and all hidden layers share the following generic structure\n",
    "\n",
    "    .. math::\n",
    "       \n",
    "       \\\\text{dropout} \\\\Big(f \\\\big( \\\\text{norm}(W x + b) \\\\big) \\\\Big) \\\\text{,} #?Yu what does 'big' and 'Big' in this equation mean?\n",
    "    \n",
    "    where\n",
    "\n",
    "    - :math:`x` is the input to the layer,\n",
    "    - :math:`W` and :math:`b` are learnanle weights,\n",
    "    - :math:`\\\\text{norm}` is a placeholder for a normalization layer (leave empty for no normalization),\n",
    "    - :math:`f` is a placeholder for an activation function (leave empty for no non-linearity), #?Yu 1, why not 'no activation' here?, 2, what does linearity mean?\n",
    "    - :math:`\\\\text{dropout}` is a placeholder for a dropout layer (leave empty for no dropout).\n",
    "\n",
    "    The output layer is not followed by normalization, non-linearity (this will be included in the loss function), nor dropout.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, feature_size, hidden_layer_sizes, num_targets, \n",
    "                 dropout_input=.0, dropout_hidden=.0, nonlinearity='Identity'): #?Yu `.0`?, 'Identity'?\n",
    "        super().__init__()\n",
    "\n",
    "        # linear layers\n",
    "        self.linear_input = nn.Linear(feature_size, hidden_layer_sizes[0])\n",
    "        self.linear_hidden_l = nn.ModuleList(\n",
    "            [nn.Linear(s, spp) for s, spp in zip(hidden_layer_sizes[:-1], hidden_layer_sizes[1:])]\n",
    "        )\n",
    "        self.linear_output = nn.Linear(hidden_layer_sizes[-1], num_targets)\n",
    "\n",
    "        # normalization layers (placeholders)\n",
    "        self.normalization_input = nn.Identity()\n",
    "        self.normalization_hidden_l = nn.ModuleList(\n",
    "            [nn.Identity() for _ in hidden_layer_sizes[1:]]\n",
    "        )\n",
    "        assert len(self.linear_hidden_l) == len(self.normalization_hidden_l), 'Something went wrong initializing the hidden layers.'\n",
    "\n",
    "        # non-linearity and dropout (placeholders)\n",
    "        self.nonlinearity = getattr(nn, nonlinearity)()\n",
    "        self.dropout_input = nn.Dropout(p=dropout_input)\n",
    "        self.dropout_hidden = nn.Dropout(p=dropout_hidden)\n",
    "        self.num_weight_matrices = len(hidden_layer_sizes) + 1 #?Yu why +1?\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_input(x)\n",
    "        x = self.normalization_input(x)\n",
    "        x = self.nonlinearity(x)\n",
    "        x = self.dropout_input(x)\n",
    "        if len(self.linear_hidden_l) > 0:\n",
    "            for linear_hidden, normalization_hidden in zip(self.linear_hidden_l, self.normalization_hidden_l):\n",
    "                x = linear_hidden(x)\n",
    "                x = normalization_hidden(x)\n",
    "                x = self.nonlinearity(x)\n",
    "                x = self.dropout_hidden(x)\n",
    "        x = self.linear_output(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self, init):\n",
    "        \"\"\"\n",
    "        Initialize all the weights using the method `init`.\n",
    "        \"\"\"\n",
    "        init(self.linear_input)\n",
    "        if len(self.linear_hidden_l) > 0:\n",
    "            for i, _ in enumerate(self.linear_hidden_l):\n",
    "                init(self.linear_hidden_l[i])\n",
    "        init(self.linear_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a4670",
   "metadata": {},
   "source": [
    "## `class NetworkLayerNorm(MultilayerPerceptron)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94da6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkLayerNorm(MultilayerPerceptron):\n",
    "    \"\"\"\n",
    "    Child class of :class:`MultilayerPerceptron` where\n",
    "\n",
    "    - normalization layers are set to :class:`~torch.nn.LayerNorm`,\n",
    "    - non-linearity is set to :class:`~torch.nn.__` which can be set by the argument nonlinearity,\n",
    "    - dropout layers are set to :class:`~torch.nn.Dropout`,\n",
    "\n",
    "    and the weights are initialized using :meth:`msra_initialization`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_size, hidden_layer_sizes, num_targets, dropout_input, dropout_hidden, nonlinearity='ReLU'):\n",
    "        super().__init__(feature_size, hidden_layer_sizes, num_targets)\n",
    "        self.normalization_input = nn.LayerNorm(\n",
    "            normalized_shape= self.linear_input.out_features,\n",
    "            elementwise_affine=False, #?Yu \n",
    "        )\n",
    "        for i, linear_hidden in enumerate(self.linear_hidden_l):\n",
    "            self.normalization_hidden_l[i] = nn.LayerNorm(\n",
    "                normalized_shape=linear_hidden.out_features,\n",
    "                elementwise_affine=False, #?Yu\n",
    "            )\n",
    "        self.nonlinearity = getattr(nn, nonlinearity if nonlinearity else 'ReLU')()\n",
    "        self.dropout_input = nn.Dropout(p=dropout_input)\n",
    "        self.dropout_hidden = nn.Dropout(p=dropout_hidden)\n",
    "        self.initialize_weights(init=msra_initialization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdb150",
   "metadata": {},
   "source": [
    "# models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b59f5c",
   "metadata": {},
   "source": [
    "## `class DotProduct(nn.Module)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c81e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(nn.Module):\n",
    "    \"\"\"\n",
    "    Class for :class:`DotProduct` models\n",
    "\n",
    "    This family of models projects compound and assay feature vectors to embeddings of size `embedding_size`, \n",
    "    typically by means of separate but similar compound and assay network encoders.\n",
    "\n",
    "    Then all the pairwise similarities between compound and assay representations are computed with their dot product.\n",
    "\n",
    "    The default :meth:`forward` method processes compound-assay interactions in COO-like format, \n",
    "    while the :meth:`forward_dense` method does it in a matrix-factorization-like manner. #?Yu matrix-factorization-like manner?\n",
    "\n",
    "    All subclasses of :class:`DotProduct` must implement the `_define_encoders` method, which has to return the compound and assay network encoders.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            compound_features_size: int,\n",
    "            assay_features_size: int,\n",
    "            embedding_size: int,\n",
    "            **kwargs\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize class.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "        compound_features_size: int\n",
    "            Input size of the compound encoder.\n",
    "        assay_features_size: int\n",
    "            Input size of the assay encoder.\n",
    "        embedding_size: int\n",
    "            Size of the association space.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.compound_features_size = compound_features_size\n",
    "        self.assay_features_size = assay_features_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.norm = kwargs.get('norm', None) # l2 norm of the output #?Yu what does `norm` mean?\n",
    "\n",
    "        self.compound_encoder, self.assay_encoder = self._define_encoders(**kwargs)\n",
    "        self.hps = kwargs #?Yu can kwargs to be a variable directly?\n",
    "        self._check_encoders()\n",
    "\n",
    "        def _define_encoders(self, **kwargs):  #?Yu current function doesn't implement the defination of encoders.\n",
    "            \"\"\"\n",
    "            All subclasses of :class:`DotProduct` must implement this method, which has to return the compound and the assay encoders.\n",
    "            The encoders can be any callables yielding the compound and assay embeddings.\n",
    "            Typically though, the encoders will be two instances of :class:`torch.nn.Module`, whose :meth:`torch.nn.Module.forward` methods provide the embeddings.\n",
    "            \"\"\"\n",
    "            raise NotImplementedError(\n",
    "                \"All subclasses of DotProduct must implement the _define_encoders method to provide  the compound and assay encoders.\"\n",
    "            )\n",
    "\n",
    "        def _check_encoders(self):\n",
    "            \"\"\"\n",
    "            Run minimal consistency checks.\n",
    "            \"\"\"\n",
    "            assert callable(self.compound_encoder)\n",
    "            assert callable(self.assay_encoder)\n",
    "        \n",
    "        def forward(\n",
    "                self,\n",
    "                compound_features: torch.Tensor,\n",
    "                assay_features: torch.Tensor\n",
    "        ) -> torch.Tensor:\n",
    "            \"\"\"\n",
    "            Take `compound_features` :math:`\\\\in \\\\mathbb{R}^{N \\\\times C} \n",
    "            and `assay_features` :math:\\\\in \\\\mathbb{R}^{N \\\\times A}`, both with :math:`N` rows.\n",
    "            Project both sets of features to :math:`D` dimensions, \n",
    "            that is, `compound_embeddings` :math:`\\\\mathbb{R}^{N \\\\times D}`\n",
    "            and `assay_embeddings` :math:`\\\\mathbb{R}^{N \\\\times D}`.\n",
    "            Compute the row-wise dot products, thus obtaining `preactivations`\n",
    "            :math:`\\\\in \\\\mathbb{R}^N`.\n",
    "\n",
    "            Params\n",
    "            ------\n",
    "            compound_features: :class:`torch.Tensor`, shape (N, compound_features_size)\n",
    "                Array of compound features.\n",
    "            assay_features: :class:`torch.Tensor`, shape (N, assay_features_size)\n",
    "                Array of assay features.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            :class:`torch.Tensor`, shape (N, )\n",
    "                Row-wise dot products of the compound and assay projections.\n",
    "            \"\"\"\n",
    "            # assert compound_features.shape[0] == assay_features.shape[0] # Dimension mismatch. #?Yu not necessary?\n",
    "\n",
    "            compound_embeddings = self.compound_encoder(compound_features) #?Yu what if the compound_features have been encoded somewhere else?\n",
    "            assay_embeddings = self.assay_encoder(assay_features)\n",
    "\n",
    "            if self.norm:\n",
    "                compound_embeddings = compound_embeddings / (torch.norm(compound_embeddings, dim=1, keepdim=True) +1e-13) #?Yu \n",
    "                assay_embeddings = assay_embeddings / (torch.norm(assay_embeddings, dim=1, keepdim=True) +1e-13)\n",
    "\n",
    "            preactivations = (compound_embeddings * assay_embeddings)\n",
    "\n",
    "            return preactivations\n",
    "        \n",
    "        def forward_dense(\n",
    "                self, \n",
    "                compound_features: torch.Tensor,\n",
    "                assay_features: torch.Tensor\n",
    "        ) -> torch.Tensor:\n",
    "            \"\"\"\n",
    "            Take `compound_features` :math:`\\\\in \\\\mathbb{R}^{N \\\\times C}\n",
    "            and `assay_features` :math:`\\\\in \\\\mathbb{R}^{M \\\\times A}`, where the number of rows :math:`N` and :math: `M` must not be the same.\n",
    "            Project both sets of features to :math:`D` dimensions, \n",
    "            that is, `compound_embeddings` :math:`\\\\in \\\\mathbb{R}^{N \\\\times D}` \n",
    "            and `assay_embeddings` :math:`\\\\in \\\\mathbb{R}^{M \\\\times D}`.\n",
    "            Compoute all the pairwise dot products by means of a matrix multiplication, thus obtaining `preactivations` :math:`\\\\in \\\\mathbb{R}^{N \\\\times M}`.\n",
    "\n",
    "            Params\n",
    "            ------\n",
    "            compound_features: :class:`torch.Tensor`, shape (N, compound_features_size)\n",
    "                Array of compound features.\n",
    "            assay_features: :class:`torch.Tensor`, shape (M, assay_features_size)\n",
    "                Array of assay features.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            :class:`torch.Tensor`, shape (N, M)\n",
    "                All pairwise dot products of the compound and assay projections.\n",
    "            \"\"\"\n",
    "            compound_embeddings = self.compound_encoder(compound_features)\n",
    "            assay_embeddings = self.assay_encoder(assay_features)\n",
    "\n",
    "            if self.norm:\n",
    "                compound_embeddings = compound_embeddings / (torch.norm(compound_embeddings, dim=1, keepdim=True) +1e-13)\n",
    "                assay_embeddings = assay_embeddings / (torch.norm(assay_embeddings, dim=1, keepdim=True) +1e-13)\n",
    "            \n",
    "            preactivations = compound_embeddings @ assay_embeddings.T\n",
    "            \n",
    "            return preactivations # the difference between the return of `forward` and `forward_dense`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1732d",
   "metadata": {},
   "source": [
    "## `class MLPlayerNorm(DotProduct)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e54eced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPlayerNorm(DotProduct):\n",
    "    \"\"\"\n",
    "    Subclass of :class:`DotProduct` where compound and assay encoders are each a multilayer perceptron (MLP) with `Layer Normalization`_. #?Yu layer normalization\n",
    "    \n",
    "    .. _`Layer Normalization`: https://arxiv.org/abs/1607.06450 #?Yu go to have a look at this paper\n",
    "    \"\"\"\n",
    "    def _define_encoder(\n",
    "            self,\n",
    "            compound_layer_sizes: List[int],\n",
    "            assay_layer_sizes: List[int],\n",
    "            dropout_input: float, #\n",
    "            dropout_hidden: float, **kwargs\n",
    "    ) -> Tuple[callable, callable]: #?Yu callable\n",
    "        \"\"\"\n",
    "        Define encoders as multilayer perceptrons with layer normalization.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "        compound_layer_sizes: list of int\n",
    "            Sizes of the hidden layers of the assay encoder.\n",
    "        assay_layer_sizes: list of int\n",
    "            Sizes of the hidden layers of the assay encoder.\n",
    "        dropout_input: float\n",
    "            Dropout rate at the input layer.\n",
    "        dropout_hidden: float\n",
    "            Dropout rate at the hidden layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple of callable\n",
    "            - Compound encoder\n",
    "            - Assay encoder\n",
    "        \"\"\"\n",
    "\n",
    "        # compound mutilayer perceptron\n",
    "        compound_encoder = NetworkLayerNorm( #?Yu why not `MultilayerPerceptron`?\n",
    "            feature_size = self.compound_feature_size, \n",
    "            hidden_layer_sizes = compound_layer_sizes, #?Yu what's the difference between `self.compound_feature_size` and `compound_layer_sizes`?\n",
    "            num_targets= self.embedding_size, #?Yu target\n",
    "            dropout_input = dropout_input,\n",
    "            dropout_hidden = dropout_hidden,\n",
    "            nonlinearity = kwargs.get('nonlinearity', 'ReLU')\n",
    "        )\n",
    "\n",
    "        # assay mutilayer perceptron\n",
    "        assay_encoder = NetworkLayerNorm( #?Yu why not `MultilayerPerceptron``\n",
    "            feature_size = self.assay_feature_size,\n",
    "            hidden_layer_sizes = assay_layer_sizes,\n",
    "            num_targets= self.embedding_size,\n",
    "            dropout_input = dropout_input,\n",
    "            dropout_hidden = dropout_hidden,\n",
    "            nonlinearity = kwargs.get('nonlinearity', 'ReLU')\n",
    "        )\n",
    "\n",
    "        return compound_encoder, assay_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb6607",
   "metadata": {},
   "source": [
    "# pretrained.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70296b2",
   "metadata": {},
   "source": [
    "## `class Pretrained(DotProduct)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pretrained(DotProduct):\n",
    "    CHECKPOINT_URL = None\n",
    "    HP_URL = None\n",
    "\n",
    "    def __init__(self, path_dir='./data/models/pretrained/', device='cuda:0', **kwargs): #?Yu prepare this checkpoint by myself\n",
    "        self.path_dir = Path(path_dir)\n",
    "        self.checkpoint = self.path_dir/\"checkpoint.pt\"\n",
    "        self.device = device\n",
    "        self.kwargs = kwargs\n",
    "        self.download_weights_if_not_present()\n",
    "\n",
    "        hp = json.load(open(self.path_dir/'hp.json', 'r'))\n",
    "        self.hparams = hp\n",
    "\n",
    "        super().__init__(**hp) #?Yu is this necessary because of this class is the subclass of DotProduct?\n",
    "\n",
    "        cp = torch.load(self.checkpoint, map_location=device)\n",
    "        self.load_state_dict(cp['model_state_dict'], strict=False)\n",
    "        logger.info(f\"Loaded pretrained model from {self.checkpoint}\")\n",
    "\n",
    "        # override forward function of compound encoder to enable forward with non-tensor #?Yu why?\n",
    "        self.compound_encoder.old_forward = self.compound_encoder.forward\n",
    "        self.compound_encoder.forward = self.compound_forward\n",
    "    \n",
    "    def download_weights_if_not_present(self, device='cpu'):\n",
    "        \"\"\" \n",
    "        download weights if not present, , which ensures that the pretrained model files (weights and hyperparameters) are available locally.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.path_dir):\n",
    "            if not self.CHECKPOINT_URL or not self.HP_URL:\n",
    "                raise ValueError(\"CHECKPOINT_URL and HP_URL must be set in the derived class.\")\n",
    "            \n",
    "            os.makedirs(self.path_dir, exist_ok=True)\n",
    "            logger.info(f\"Downloading checkpoint.pt from {self.CHECKPOINT_URL} to {self.path_dir}\") #?Yu prepare this checkpoint by myself\n",
    "            os.system(f\"wegt {self.CHECKPOINT_URL} -O {self.checkpoint}\")\n",
    "            os.system(f\"wegt {self.HP_URL} -O {Path(self.path_dir)/'hp.json'}\")\n",
    "\n",
    "    def prepro_smiles(self, smi, no_grad=True): #?Yu If compound is encoded as previously, is it okay to remove this function?\n",
    "        \"\"\"\n",
    "        Preprocess smiles for compound encoder.\n",
    "        \"\"\"\n",
    "        fp_size = self.compound_encoder.linear_input.weight.shape[1] #?Yu what does this mean?\n",
    "        fp_input = convert_smiles_to_fp(smi, fp_size=fp_size, which=self.hparams['compound_mode'], njobs=1).astype(np.float32)\n",
    "        compound_features = torch.tensor(fp_input).to(self.device)\n",
    "        return compound_features\n",
    "\n",
    "    def encode_smiles(self, smis, no_grad=True): \n",
    "        \"\"\"Encode SMILES\"\"\"\n",
    "        compound_features = self.prepro_smiles(smis)\n",
    "        with torch.no_grad() if no_grad else torch.enable_grad():\n",
    "            compound_features = self.compound_encoder(compound_features) #?Yu if compound_features already, why is it necessary to use compound_encoder again?\n",
    "        return compound_features\n",
    "    \n",
    "    def compound_forward(self, x):\n",
    "        \"\"\"\n",
    "        compound_encoder forward function, takes smiles or features as tensor for input\n",
    "        \"\"\"\n",
    "        if isinstance(x[0], str):\n",
    "            x = self.prepro_smiles(x)\n",
    "        \n",
    "        return self.compound_encoder.old_forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6b5c7",
   "metadata": {},
   "source": [
    "## `class PretrainedCLAMP(MLPlayerNorm, Pretrained)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedCLAMP(MLPlayerNorm, Pretrained):\n",
    "    \"\"\"\n",
    "    This class mainly prepare the assay information.\n",
    "    \"\"\"\n",
    "    CHECKPOINT_URL = \"https://cloud.ml.jku.at/s/7nxgpAQrTr69Rp2/download/checkpoint.pt\" #?Yu prepare this checkpoint by myself\n",
    "    HP_URL = \"https://cloud.ml.jku.at/s/dRX9TWPrF7WqnHd/download/hp.json\" #?Yu prepare this hp by myself\n",
    "\n",
    "    def __init__(self, path_dir='./data/models/clamp_clip', device='cuda:0', **kwargs): #?Yu prepare the `clamp_clip` by myself, too?\n",
    "        super().__init__(path_dir, device, **kwargs)\n",
    "        self.compound_feature_size = 8192 #?Yu shall I change it later?\n",
    "        self.assay_feature_size = 768 #?Yu why is it 768?\n",
    "        self.text_encoder = None # encoder from clip\n",
    "\n",
    "        self.assay_encoder.old_forward = self.assay_encoder.forward  #?Yu why\n",
    "        self.assay_encoder.forward = self.assay_forward #?Yu why\n",
    "\n",
    "    def load_clip_text_encoder(self):\n",
    "        import clip\n",
    "        model_clip, preprocess = clip.load(\"ViT-B/32\", device=self.device)\n",
    "        self.text_encoder = model_clip\n",
    "\n",
    "    def prepro_text(self, txt, no_grad=True): #?Yu If the assay text is encoded previously, is it okay to remove this function?\n",
    "        \"\"\"Preprocess text for assay encoder\"\"\"\n",
    "        import clip\n",
    "        if not self.text_encoder: # if not loaded yet. self.text_encoder being None is under this condition.\n",
    "            self.load_clip_text_encoder()\n",
    "        tokenized_text = clip.tokenize(txt, truncate=True).to(self.device)\n",
    "        assay_features = self.text_encoder.encode_text(tokenized_text).float().to(self.device)\n",
    "        if no_grad:\n",
    "            assay_features = assay_features.detach().requires_grad_(False)\n",
    "        \n",
    "        return assay_features\n",
    "    \n",
    "    def encode_text(self, txt, no_grad=True):\n",
    "        \"\"\"Encode text\"\"\"\n",
    "        assay_features = self.prepro_text(txt)\n",
    "        with torch.no_grad() if no_grad else torch.enable_grad():\n",
    "            assay_features = self.assay_encoder(assay_features)\n",
    "\n",
    "        return assay_features\n",
    "    \n",
    "    def assay_forward(self, x):\n",
    "        \"\"\"assay_encoder forward function, takes list of text str or features tensor as input\"\"\"\n",
    "        if isinstance(x[0], str):\n",
    "            x = self.prepro_text(x, no_grad=True)\n",
    "        return self.assay_encoder.old_forward(x)\n",
    "    \n",
    "    def prepro_text(self, txt, no_grad=True):\n",
    "        \"\"\"preprocess text for assay encoder\"\"\"\n",
    "        import clip\n",
    "        if not self.text_encoder:\n",
    "            self.load_clip_text_encoder()\n",
    "        tokenized_text = clip.tokenize(txt, truncate=True).to(self.device) \n",
    "        assay_features = self.text_encoder.encode_text(tokenized_text).float().to(self.device)\n",
    "        if no_grad:\n",
    "            assay_features = assay_features.detach().requires_grad_(False)\n",
    "        return assay_features\n",
    "\n",
    "    def encode_text(self, txt, no_grad=True):\n",
    "        \"\"\"encode text\"\"\"\n",
    "        assay_features = self.prepro_text(txt)\n",
    "        with torch.no_grad() if no_grad else torch.enable_grad():\n",
    "            assay_features = self.assay_encoder(assay_features)\n",
    "        return assay_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
