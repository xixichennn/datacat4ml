{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda environment: pyg (Python 3.9.16)\n",
    "import os\n",
    "import warnings\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "try:\n",
    "    import horovod.torch as hvd\n",
    "except ImportError:\n",
    "    hvd = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Concetps in Distributed Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank and Word Size\n",
    "- **rank**: The unique ID assigned to each process. Rank 0 is usually the master process\n",
    "- **world size**: Total number of processes participating in the training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backend\n",
    "The distributed communication library used for training:\n",
    "- **NCCL**: Best for GPU-based communication (default for CUDA).\n",
    "- **Gloo**: Supports CPU and GPU communication.\n",
    "- **Horovod**: An alternative distributed framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local vs. Global Rank\n",
    "- **local rank**: The rank of a process within a singel machine.\n",
    "- **global rank**: The rank across all machines in a distributed system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Device Handling ####\n",
    "def is_global_master(args):\n",
    "    return args.rank == 0\n",
    "\n",
    "\n",
    "def is_local_master(args):\n",
    "    return args.local_rank == 0\n",
    "\n",
    "\n",
    "def is_master(args, local=False):\n",
    "    return is_local_master(args) if local else is_global_master(args)\n",
    "\n",
    "def is_device_available(device):\n",
    "    device_type = torch.device(device).type\n",
    "    is_avail = False\n",
    "    is_known = False\n",
    "    if device_type == 'cuda':\n",
    "        is_avail = torch.cuda.is_available()\n",
    "        is_known = True\n",
    "    elif device_type == 'npu':\n",
    "        # NOTE autoload device extension needed for this not to error out on this check\n",
    "        is_avail = torch.npu.is_available()\n",
    "        is_known = True\n",
    "    elif device_type == 'mps':\n",
    "        is_avail = torch.backends.mps.is_available()\n",
    "        is_known = True\n",
    "    elif device_type == 'cpu':\n",
    "        is_avail = True\n",
    "        is_known = True\n",
    "\n",
    "    return is_avail, is_known\n",
    "\n",
    "def set_device(device):\n",
    "    if device.startswith('cuda:'):\n",
    "        torch.cuda.set_device(device)\n",
    "    elif device.startswith('npu:'):\n",
    "        torch.npu.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distributed Environment Detection ###\n",
    "def is_using_horovod():\n",
    "    # NOTE w/ horovod run, OMPI vars should be set, but w/ SLURM PMI vars will be set\n",
    "    # Differentiating between horovod and DDP use via SLURM may not be possible, so horovod arg still required...\n",
    "    ompi_vars = [\"OMPI_COMM_WORLD_RANK\", \"OMPI_COMM_WORLD_SIZE\"]\n",
    "    pmi_vars = [\"PMI_RANK\", \"PMI_SIZE\"]\n",
    "    if all([var in os.environ for var in ompi_vars]) or all([var in os.environ for var in pmi_vars]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_using_distributed():\n",
    "    if 'WORLD_SIZE' in os.environ:\n",
    "        return int(os.environ['WORLD_SIZE']) > 1\n",
    "    if 'SLURM_NTASKS' in os.environ:\n",
    "        return int(os.environ['SLURM_NTASKS']) > 1\n",
    "    return False\n",
    "\n",
    "\n",
    "def world_info_from_env():\n",
    "    local_rank = 0\n",
    "    for v in ('LOCAL_RANK', 'MPI_LOCALRANKID', 'SLURM_LOCALID', 'OMPI_COMM_WORLD_LOCAL_RANK'):\n",
    "        if v in os.environ:\n",
    "            local_rank = int(os.environ[v])\n",
    "            break\n",
    "    global_rank = 0\n",
    "    for v in ('RANK', 'PMI_RANK', 'SLURM_PROCID', 'OMPI_COMM_WORLD_RANK'):\n",
    "        if v in os.environ:\n",
    "            global_rank = int(os.environ[v])\n",
    "            break\n",
    "    world_size = 1\n",
    "    for v in ('WORLD_SIZE', 'PMI_SIZE', 'SLURM_NTASKS', 'OMPI_COMM_WORLD_SIZE'):\n",
    "        if v in os.environ:\n",
    "            world_size = int(os.environ[v])\n",
    "            break\n",
    "\n",
    "    return local_rank, global_rank, world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Distributed Initialization ###\n",
    "def init_distributed_device(args):\n",
    "    # Distributed training = training on more than one GPU.\n",
    "    # Works in both single and multi-node scenarios.\n",
    "    args.distributed = False\n",
    "    args.world_size = 1\n",
    "    args.rank = 0  # global rank\n",
    "    args.local_rank = 0\n",
    "    result = init_distributed_device_so(\n",
    "        device=getattr(args, 'device', 'cuda'),\n",
    "        dist_backend=getattr(args, 'dist_backend', None),\n",
    "        dist_url=getattr(args, 'dist_url', None),\n",
    "        horovod=getattr(args, 'horovod', False),\n",
    "        no_set_device_rank=getattr(args, 'no_set_device_rank', False),\n",
    "    )\n",
    "    args.device = result['device']\n",
    "    args.world_size = result['world_size']\n",
    "    args.rank = result['global_rank']\n",
    "    args.local_rank = result['local_rank']\n",
    "    args.distributed = result['distributed']\n",
    "    device = torch.device(args.device)\n",
    "    return device\n",
    "\n",
    "\n",
    "def init_distributed_device_so(\n",
    "        device: str = 'cuda',\n",
    "        dist_backend: Optional[str] = None,\n",
    "        dist_url: Optional[str] = None,\n",
    "        horovod: bool = False,\n",
    "        no_set_device_rank: bool = False,\n",
    "):\n",
    "    # Distributed training = training on more than one GPU.\n",
    "    # Works in both single and multi-node scenarios.\n",
    "    distributed = False\n",
    "    world_size = 1\n",
    "    global_rank = 0\n",
    "    local_rank = 0\n",
    "    device_type, *device_idx = device.split(':', maxsplit=1)\n",
    "    is_avail, is_known = is_device_available(device_type)\n",
    "    if not is_known:\n",
    "        warnings.warn(f\"Device {device} was not known and checked for availability, trying anyways.\")\n",
    "    elif not is_avail:\n",
    "        warnings.warn(f\"Device {device} was not available, falling back to CPU.\")\n",
    "        device_type = device = 'cpu'\n",
    "\n",
    "    if horovod:\n",
    "        import horovod.torch as hvd\n",
    "        assert hvd is not None, \"Horovod is not installed\"\n",
    "        hvd.init()\n",
    "        local_rank = int(hvd.local_rank())\n",
    "        global_rank = hvd.rank()\n",
    "        world_size = hvd.size()\n",
    "        distributed = True\n",
    "    elif is_using_distributed():\n",
    "        if dist_backend is None:\n",
    "            dist_backends = {\n",
    "                \"cuda\": \"nccl\",\n",
    "                \"hpu\": \"hccl\",\n",
    "                \"npu\": \"hccl\",\n",
    "                \"xpu\": \"ccl\",\n",
    "            }\n",
    "            dist_backend = dist_backends.get(device_type, 'gloo')\n",
    "\n",
    "        dist_url = dist_url or 'env://'\n",
    "\n",
    "        if 'SLURM_PROCID' in os.environ:\n",
    "            # DDP via SLURM\n",
    "            local_rank, global_rank, world_size = world_info_from_env()\n",
    "            # SLURM var -> torch.distributed vars in case needed\n",
    "            os.environ['LOCAL_RANK'] = str(local_rank)\n",
    "            os.environ['RANK'] = str(global_rank)\n",
    "            os.environ['WORLD_SIZE'] = str(world_size)\n",
    "            torch.distributed.init_process_group(\n",
    "                backend=dist_backend,\n",
    "                init_method=dist_url,\n",
    "                world_size=world_size,\n",
    "                rank=global_rank,\n",
    "            )\n",
    "        else:\n",
    "            # DDP via torchrun, torch.distributed.launch\n",
    "            local_rank, _, _ = world_info_from_env()\n",
    "            torch.distributed.init_process_group(\n",
    "                backend=dist_backend,\n",
    "                init_method=dist_url,\n",
    "            )\n",
    "            world_size = torch.distributed.get_world_size()\n",
    "            global_rank = torch.distributed.get_rank()\n",
    "        distributed = True\n",
    "\n",
    "    if distributed and not no_set_device_rank and device_type not in ('cpu', 'mps'):\n",
    "        # Ignore manually specified device index in distributed mode and\n",
    "        # override with resolved local rank, fewer headaches in most setups.\n",
    "        if device_idx:\n",
    "            warnings.warn(f'device index {device_idx[0]} removed from specified ({device}).')\n",
    "        device = f'{device_type}:{local_rank}'\n",
    "        set_device(device)\n",
    "\n",
    "    return dict(\n",
    "        device=device,\n",
    "        global_rank=global_rank,\n",
    "        local_rank=local_rank,\n",
    "        world_size=world_size,\n",
    "        distributed=distributed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Communication Utilities ###\n",
    "def broadcast_object(args, obj, src=0):\n",
    "    # broadcast a pickle-able python object from rank-0 to all ranks\n",
    "    if args.horovod:\n",
    "        return hvd.broadcast_object(obj, root_rank=src)\n",
    "    else:\n",
    "        if args.rank == src:\n",
    "            objects = [obj]\n",
    "        else:\n",
    "            objects = [None]\n",
    "        dist.broadcast_object_list(objects, src=src)\n",
    "        return objects[0]\n",
    "\n",
    "\n",
    "def all_gather_object(args, obj, dst=0):\n",
    "    # gather a pickle-able python object across all ranks\n",
    "    if args.horovod:\n",
    "        return hvd.allgather_object(obj)\n",
    "    else:\n",
    "        objects = [None for _ in range(args.world_size)]\n",
    "        dist.all_gather_object(objects, obj)\n",
    "        return objects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
