{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conducts hyperparameter tuning for the models in the pipeline.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "# inner modules\n",
    "sys.path.append(\"/scratch/yuc94/ML\")\n",
    "from OpioML.Scripts.const import File_paths, Tasks, Confidence_scores, Use_clusterings, Use_smotes, Descriptors, HYPERPARAM_SPACE_DIR, BEST_CONFIG_ASSAYWISE_DIR, DATASETS_DIR\n",
    "from OpioML.Scripts.pipeline.data import Data\n",
    "from OpioML.Scripts.model_dev.mlp import MLPR, MLPC\n",
    "from OpioML.Scripts.model_dev.ml import RFC, RFR, SVRR, SVCC, KNNR, KNNC, GBC, GBR\n",
    "from OpioML.Scripts.model_dev.tune_alpha_low import BayesianOptimization4reg, BayesianOptimization4cls\n",
    "from OpioML.Scripts.utils import mkdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================  Hyperparameter tuning ====================\n",
    "N_CALLS = 50 # n optimization attempts\n",
    "algo4reg = [RFR, SVRR, KNNR, GBR]\n",
    "algo4cls = [RFC, SVCC, KNNC, GBC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_tune(file_path: File_paths = DATASETS_DIR, task: str = 'cls', confidence_score: int=8, \n",
    "                    use_clustering: int=1, thr_class: int=6,\n",
    "                    use_smote: int=1, descriptor: str='ECFP4'):\n",
    "    \n",
    "    use_smote = bool(use_smote)\n",
    "    use_clustering = bool(use_clustering)\n",
    "\n",
    "    print(f\"file_path: {file_path}\\n\")\n",
    "    print(f\"task: {task}\\n\")\n",
    "    print(f\"confidence_score: {confidence_score}\\n\")\n",
    "    print(f\"thr_class: {thr_class}\\n\")\n",
    "    print(f\"use_clustering: {use_clustering}\\n\")\n",
    "\n",
    "    file_folder = os.path.join(file_path, 'assaywise_splited', task, 'confidence_score'+'_'+str(confidence_score), 'thr_class'+'_'+str(thr_class), 'use_clustering' +'_'+str(use_clustering))\n",
    "    filenames = os.listdir(file_folder)\n",
    "    for filename in tqdm(filenames):\n",
    "        print(f\"file: {filename}\\n\")\n",
    "\n",
    "        print(f\"use_smote: {use_smote}\\n\")\n",
    "        if task == 'reg':\n",
    "            use_smote = False\n",
    "            algos = algo4reg\n",
    "            bayesianopt = BayesianOptimization4reg\n",
    "        elif task == 'cls':\n",
    "            use_smote = use_smote\n",
    "            algos = algo4cls\n",
    "            bayesianopt = BayesianOptimization4cls\n",
    "\n",
    "        # create a Data object\n",
    "        try:\n",
    "            data = Data(file_folder, filename, task, use_smote)\n",
    "\n",
    "            print(f\"descriptor: {descriptor}\\n\")\n",
    "\n",
    "            # Featurize SMILES strings with the given descriptor\n",
    "            data.featurize_data(descriptor)            \n",
    "            \n",
    "            if task == 'cls' and use_smote:\n",
    "                data.balance_data()\n",
    "                data.shuffle()\n",
    "            else:\n",
    "                data.shuffle()\n",
    "\n",
    "            for algo in algos:\n",
    "                try:\n",
    "                    # Get the hyperparameter space for the given algorithm\n",
    "                    print(f\"read hyperparam space for {algo.__name__} ...\")\n",
    "                    hyperparam_space = (os.path.join(HYPERPARAM_SPACE_DIR, f\"{algo.__name__}.yml\"))\n",
    "                    print(f'Done')\n",
    "\n",
    "                    # Perform hyperparameter tuning using Bayesian optimization\n",
    "                    print(f\"tuning hyperparam for {algo.__name__} ...\")\n",
    "                    opt = bayesianopt(algo, task)\n",
    "                    if data.x_smote_train is not None:\n",
    "                        print(f\"smote is used\")\n",
    "                        opt.optimize(data.x_smote_train, data.y_smote_train, hyperparam_space, n_calls= N_CALLS)\n",
    "                    else:\n",
    "                        print(f\"smote is not used\")\n",
    "                        opt.optimize(data.x_train, data.y_train, hyperparam_space, n_calls= N_CALLS)\n",
    "                    print(f'Done')\n",
    "\n",
    "                    # Save best hyperparameters as a yaml file\n",
    "                    print(f\"save best hyperparam for {algo.__name__} ...\")\n",
    "                    output_dir = os.path.join(BEST_CONFIG_ASSAYWISE_DIR, task, 'confidence_score'+'_'+str(confidence_score), 'thr_class'+'_'+str(thr_class), 'use_clustering' +'_'+str(use_clustering), 'use_smote'+'_'+str(use_smote), filename[:-10])\n",
    "                    mkdirs(output_dir)\n",
    "                    opt.save_config(os.path.join(output_dir, f\"{algo.__name__}_{descriptor}.yml\"))\n",
    "                    print(\"Done\")\n",
    "\n",
    "                    # Plot the optimiztion progress and save the figure in the output_dir\n",
    "                    print(f\"plot optimization progress for {algo.__name__} ...\")\n",
    "                    opt.plot_progress(os.path.join(output_dir, f\"{algo.__name__}_{descriptor}.png\"))\n",
    "                    print(\"Done\")\n",
    "                \n",
    "                except:\n",
    "                    warnings.warn(f\" -- FAILED {filename}-{task}-use_smote_{use_smote}{algo.__name__}-{descriptor} --\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            warnings.warn(f\" -- FAILED to create Data object for {filename}: {e} --\")\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
