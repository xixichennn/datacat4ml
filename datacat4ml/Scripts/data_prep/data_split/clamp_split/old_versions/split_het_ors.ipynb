{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datacat4ml.utils import mkdirs, get_df_name\n",
    "from datacat4ml.const import *\n",
    "#from datacat4ml.Scripts.data_prep.data_split.split_utils "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the heterogenous datasets of ORs\n",
    "based on the train_test_split of categorized datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_data_spliter(task:str='cls', confidence_score:int=9, thr_class:int=7, use_clustering: bool=True,\n",
    "                        target:str='mor', std_type:str='Ki', effect:str='antag', assay:str='G_GTP'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Split the merged data into train and test sets based on the corresponding categorized data.\n",
    "    \"\"\"\n",
    "    # load merged data\n",
    "    merged_df  = pd.read_csv(os.path.join(FETCH_DATA_DIR, 'curated', task, 'confidence_score'+'_'+str(confidence_score), \n",
    "                                               'thr_class'+'_'+str(thr_class), f\"{target}_{std_type}_final.csv\")).drop(columns=['Unnamed: 0'])\n",
    "    # load categorized data\n",
    "    cat_df = pd.read_csv(os.path.join(DATASETS_DIR, 'random_splited', task, 'confidence_score'+'_'+str(confidence_score),\n",
    "                                                                'thr_class'+'_'+str(thr_class), 'use_clustering'+'_'+str(use_clustering),\n",
    "                                                                f\"{target}_{effect}_{assay}_{std_type}_final.csv\")).drop(columns=['Unnamed: 0'])\n",
    "    # for cat_df\n",
    "    # get indices of 'test' rows in categorized data\n",
    "    cat_test_idx = cat_df[cat_df['split'] == 'test'].index.tolist()\n",
    "    cat_test_smiles = cat_df.iloc[cat_test_idx]['smiles'].tolist()\n",
    "\n",
    "    # for merged_df\n",
    "    # identify indices of 'CuratedSmiles' in merged data that are in categorized test smiles\n",
    "    mer_test_idx = merged_df[merged_df['CuratedSmiles'].isin(cat_test_smiles)].index.tolist()\n",
    "    # add a 'split' column to merged data, setting 'test' for test indices and 'train' for others\n",
    "    merged_df['split'] = ['test' if i in mer_test_idx else 'train' for i in range(len(merged_df))]\n",
    "    # add a column 'cliff_mol'  \n",
    "    merged_df['cliff_mol'] = np.nan\n",
    "    # populate 'cliff_mol' for rows in test indices using values from categorized data\n",
    "    for i in mer_test_idx:\n",
    "        merged_df.loc[i, 'cliff_mol'] = cat_df.loc[\n",
    "            cat_df[cat_df['smiles'] == (merged_df.loc[i, 'CuratedSmiles'])].index[0], \n",
    "            'cliff_mol']\n",
    "        \n",
    "    if task == 'cls':\n",
    "        splited_merged_df= pd.DataFrame({'molecule_chembl_id': merged_df['molecule_chembl_id'].tolist(),\n",
    "                                        'smiles': merged_df['CuratedSmiles'].tolist(),\n",
    "                                        'exp_mean [nM]': (10**abs(np.array(merged_df['pstandard_value_mean']))).tolist(),\n",
    "                                        'pstandard_value_mean': merged_df['pstandard_value_mean'].tolist(),\n",
    "                                        'cliff_mol': merged_df['cliff_mol'].tolist(),\n",
    "                                        'y(activity)': merged_df['activity'].tolist(),\n",
    "                                        'split': merged_df['split'].tolist(),\n",
    "                                        })\n",
    "\n",
    "        \n",
    "    elif task == 'reg':\n",
    "        splited_merged_df= pd.DataFrame({'molecule_chembl_id': merged_df['molecule_chembl_id'].tolist(),\n",
    "                                        'smiles': merged_df['CuratedSmiles'].tolist(),\n",
    "                                        'exp_mean [nM]': (10**abs(np.array(merged_df['pstandard_value_mean']))).tolist(),\n",
    "                                        'y(pstandard_value_mean)':merged_df['pstandard_value_mean'].tolist(),\n",
    "                                        'cliff_mol': merged_df['cliff_mol'].tolist(),\n",
    "                                        'activity':merged_df['activity'].tolist(),\n",
    "                                        'split':merged_df['split'].tolist()})\n",
    "    splited_merged_df['file_path'] = 'merged'\n",
    "    splited_merged_df['task'] = task\n",
    "    splited_merged_df['confidence_score'] = confidence_score\n",
    "    splited_merged_df['thr_class'] = thr_class\n",
    "    splited_merged_df['use_clustering'] = use_clustering\n",
    "    splited_merged_df['target'] = target\n",
    "    splited_merged_df['std_type'] = std_type\n",
    "    splited_merged_df['effect'] = effect    \n",
    "    splited_merged_df['assay'] = assay\n",
    "    \n",
    "    # save splited_merged_df as csv file\n",
    "    output_folder = os.path.join(FETCH_DATA_DIR, 'assaywise_splited', task, 'confidence_score'+'_'+str(confidence_score),\n",
    "                                    'thr_class'+'_'+str(thr_class), 'use_clustering'+'_'+str(use_clustering))\n",
    "    mkdirs(output_folder) # make directory if not exist\n",
    "    splited_merged_df.to_csv(os.path.join(output_folder, f\"{target}_{std_type}_{effect}_{assay}_assaywise-splited.csv\"))\n",
    "\n",
    "    return splited_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in Tasks:\n",
    "    for confidence_score in Confidence_scores:\n",
    "        for thr_class in Thr_classes:\n",
    "            for use_clustering in Use_clusterings:\n",
    "                folder_path = os.path.join(DATASETS_DIR, 'curated', task, 'confidence_score'+'_'+str(confidence_score), 'thr_class'+'_'+str(thr_class))\n",
    "                files = os.listdir(folder_path)\n",
    "                dfs = []\n",
    "                for file in files:\n",
    "                    df = pd.read_csv(os.path.join(folder_path, file)).drop(columns=['Unnamed: 0'])\n",
    "                    dfs.append(df)\n",
    "                print(f\"Number of files: {len(dfs)}\")\n",
    "                for df in dfs:\n",
    "                    if not df.empty:\n",
    "                        # assign the first value in 'target' column to the variable target\n",
    "                        target = df['target'].tolist()[0]\n",
    "                        effect = df['effect'].tolist()[0]\n",
    "                        assay = df['assay'].tolist()[0]\n",
    "                        std_type = df['std_type'].tolist()[0]\n",
    "\n",
    "                        print(target, effect, assay, std_type)\n",
    "                        try:\n",
    "                            merged_data_spliter(task=task, confidence_score=confidence_score, thr_class=thr_class, use_clustering=use_clustering,\n",
    "                                            target=target, std_type=std_type, effect=effect, assay=assay)\n",
    "                        # print the error message\n",
    "                        except Exception as e:\n",
    "                            warnings.warn(f\"Error in {target} {effect} {assay} {std_type}:\\n{e}\"    )\n",
    "                    else:\n",
    "                        print(\"Empty DataFrame detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
